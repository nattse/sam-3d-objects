{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leelab/anaconda3/envs/sam3d-objects/lib/python3.11/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp 1.10.0 initialized:\n",
      "   CUDA Toolkit 12.8, Driver 12.4\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA GeForce RTX 4090\" (24 GiB, sm_89, mempool enabled)\n",
      "     \"cuda:1\"   : \"NVIDIA GeForce RTX 4090\" (24 GiB, sm_89, mempool enabled)\n",
      "   CUDA peer access:\n",
      "     Not supported\n",
      "   Kernel cache:\n",
      "     /home/leelab/.cache/warp/1.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-25 05:59:23.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36mset_attention_backend\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mGPU name is NVIDIA GeForce RTX 4090\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-25 05:59:24.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.tdfy_dit.modules.sparse\u001b[0m:\u001b[36m__from_env\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1m[SPARSE] Backend: spconv, Attention: sdpa\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:26.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.tdfy_dit.modules.attention\u001b[0m:\u001b[36m__from_env\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1m[ATTENTION] Using backend: sdpa\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPARSE][CONV] spconv algo: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-25 05:59:27.109\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msam3d_objects.data.dataset.tdfy.preprocessor\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[33m\u001b[1mNo rgb pointmap normalizer provided, using scale + shift \u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:27.110\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msam3d_objects.data.dataset.tdfy.preprocessor\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[33m\u001b[1mNo rgb pointmap normalizer provided, using scale + shift \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import imageio\n",
    "import uuid\n",
    "from IPython.display import Image as ImageDisplay\n",
    "from inference import Inference, ready_gaussian_for_video_rendering, render_video, load_image, load_mask, load_single_mask, display_image, make_scene, interactive_visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-25 05:59:27.131\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msam3d_objects.data.dataset.tdfy.preprocessor\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[33m\u001b[1mNo rgb pointmap normalizer provided, using scale + shift \u001b[0m\n",
      "/home/leelab/anaconda3/envs/sam3d-objects/lib/python3.11/site-packages/moge/model/v1.py:171: UserWarning: The following deprecated/invalid arguments are ignored: {'output_mask': True, 'split_head': True}\n",
      "  warnings.warn(f\"The following deprecated/invalid arguments are ignored: {deprecated_kwargs}\")\n",
      "\u001b[32m2025-11-25 05:59:31.087\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msam3d_objects.data.dataset.tdfy.preprocessor\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[33m\u001b[1mNo rgb pointmap normalizer provided, using scale + shift \u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:31.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mself.device: cuda\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:31.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mCUDA_VISIBLE_DEVICES: None\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:31.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mActually using GPU: 0\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:31.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36minit_pose_decoder\u001b[0m:\u001b[36m295\u001b[0m - \u001b[1mUsing pose decoder: ScaleShiftInvariant\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:31.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m131\u001b[0m - \u001b[1mLoading model weights...\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:31.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.io\u001b[0m:\u001b[36mload_model_from_checkpoint\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoading checkpoint from /home/leelab/sam3dnate/sam-3d-objects/notebook/../checkpoints/hf/ss_generator.ckpt\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:35.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.io\u001b[0m:\u001b[36mload_model_from_checkpoint\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoading checkpoint from /home/leelab/sam3dnate/sam-3d-objects/notebook/../checkpoints/hf/slat_generator.ckpt\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:36.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.io\u001b[0m:\u001b[36mload_model_from_checkpoint\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoading checkpoint from /home/leelab/sam3dnate/sam-3d-objects/notebook/../checkpoints/hf/ss_decoder.ckpt\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:36.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.io\u001b[0m:\u001b[36mload_model_from_checkpoint\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoading checkpoint from /home/leelab/sam3dnate/sam-3d-objects/notebook/../checkpoints/hf/slat_decoder_gs.ckpt\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:36.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.io\u001b[0m:\u001b[36mload_model_from_checkpoint\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoading checkpoint from /home/leelab/sam3dnate/sam-3d-objects/notebook/../checkpoints/hf/slat_decoder_gs_4.ckpt\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:36.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.io\u001b[0m:\u001b[36mload_model_from_checkpoint\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoading checkpoint from /home/leelab/sam3dnate/sam-3d-objects/notebook/../checkpoints/hf/slat_decoder_mesh.ckpt\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:36.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.dit.embedder.dino\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mLoading DINO model: dinov2_vitl14_reg from facebookresearch/dinov2 (source: github)\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:37.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.dit.embedder.dino\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mLoaded DINO model - type: <class 'dinov2.models.vision_transformer.DinoVisionTransformer'>, embed_dim: 1024, patch_size: (14, 14)\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:37.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.dit.embedder.dino\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mLoading DINO model: dinov2_vitl14_reg from facebookresearch/dinov2 (source: github)\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:37.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.dit.embedder.dino\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mLoaded DINO model - type: <class 'dinov2.models.vision_transformer.DinoVisionTransformer'>, embed_dim: 1024, patch_size: (14, 14)\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:37.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.io\u001b[0m:\u001b[36mload_model_from_checkpoint\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoading checkpoint from /home/leelab/sam3dnate/sam-3d-objects/notebook/../checkpoints/hf/ss_generator.ckpt\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:39.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.dit.embedder.dino\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mLoading DINO model: dinov2_vitl14_reg from facebookresearch/dinov2 (source: github)\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:40.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.dit.embedder.dino\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mLoaded DINO model - type: <class 'dinov2.models.vision_transformer.DinoVisionTransformer'>, embed_dim: 1024, patch_size: (14, 14)\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:40.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.dit.embedder.dino\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mLoading DINO model: dinov2_vitl14_reg from facebookresearch/dinov2 (source: github)\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:40.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.dit.embedder.dino\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mLoaded DINO model - type: <class 'dinov2.models.vision_transformer.DinoVisionTransformer'>, embed_dim: 1024, patch_size: (14, 14)\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:40.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.io\u001b[0m:\u001b[36mload_model_from_checkpoint\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoading checkpoint from /home/leelab/sam3dnate/sam-3d-objects/notebook/../checkpoints/hf/slat_generator.ckpt\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:41.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36moverride_ss_generator_cfg_config\u001b[0m:\u001b[36m436\u001b[0m - \u001b[1mss_generator parameters: inference_steps=25, cfg_strength=7, cfg_interval=[0, 500], rescale_t=3, cfg_strength_pm=0.0\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:41.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36moverride_slat_generator_cfg_config\u001b[0m:\u001b[36m458\u001b[0m - \u001b[1mslat_generator parameters: inference_steps=25, cfg_strength=1, cfg_interval=[0, 500], rescale_t=1\u001b[0m\n",
      "\u001b[32m2025-11-25 05:59:41.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mLoading model weights completed!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "PATH = os.getcwd()\n",
    "TAG = \"hf\"\n",
    "config_path = f\"{PATH}/../checkpoints/{TAG}/pipeline.yaml\"\n",
    "inference = Inference(config_path, compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load input image to lift to 3D (single object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = f\"{PATH}/images/shutterstock_stylish_kidsroom_1640806567/image.png\"\n",
    "IMAGE_NAME = os.path.basename(os.path.dirname(IMAGE_PATH))\n",
    "\n",
    "image = load_image(IMAGE_PATH)\n",
    "mask = load_single_mask(os.path.dirname(IMAGE_PATH), index=14)\n",
    "display_image(image, masks=[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Gaussian Splat (single view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "output = inference(image, mask, seed=42)\n",
    "\n",
    "# export gaussian splat (as point cloud)\n",
    "output[\"gs\"].save_ply(f\"{PATH}/gaussians/single/{IMAGE_NAME}.ply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. (Optional) Multi-view conditioning from an auxiliary directory\n",
    "Provide extra camera views in a directory and pass it as the third argument to `inference(image, mask, aux_views_dir)`.\n",
    "The snippet below fabricates a tiny auxiliary set so you can see the call pattern; replace `AUX_VIEWS_DIR` with your own folder of RGBA/RGB images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "InferencePipelinePointMap.run() got an unexpected keyword argument 'aux_views'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#AUX_VIEWS_DIR.mkdir(parents=True, exist_ok=True)\u001b[39;00m\n\u001b[32m     12\u001b[39m MULTI_VIEW_NAME = AUX_VIEWS_DIR.name\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m output_multiview = \u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maux_views\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mAUX_VIEWS_DIR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m os.makedirs(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/gaussians/multiview\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     15\u001b[39m output_multiview[\u001b[33m\"\u001b[39m\u001b[33mgs\u001b[39m\u001b[33m\"\u001b[39m].save_ply(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/gaussians/multiview/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMULTI_VIEW_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.ply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sam3dnate/sam-3d-objects/notebook/inference.py:144\u001b[39m, in \u001b[36mInference.__call__\u001b[39m\u001b[34m(self, image, mask, aux_views, seed, pointmap)\u001b[39m\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    142\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnsupported image type for masking.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43maux_views\u001b[49m\u001b[43m=\u001b[49m\u001b[43maux_views\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstage1_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_mesh_postprocess\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_texture_baking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_layout_postprocess\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_vertex_color\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstage1_inference_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpointmap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpointmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: InferencePipelinePointMap.run() got an unexpected keyword argument 'aux_views'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "IMG_DIR = '/home/leelab/sam3dnate/testImgs'\n",
    "image = load_image(os.path.join(IMG_DIR, 'G1_run1_mouse-frame_synced_frame2230.jpg'))\n",
    "mask = load_mask(os.path.join(IMG_DIR, 'G1_run1_mouse-frame_synced_frame2230.png'))\n",
    "\n",
    "AUX_VIEWS_DIR = Path(f\"{IMG_DIR}/aux\")\n",
    "#AUX_VIEWS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MULTI_VIEW_NAME = AUX_VIEWS_DIR.name\n",
    "output_multiview = inference(image, mask, aux_views=str(AUX_VIEWS_DIR), seed=7)\n",
    "os.makedirs(f\"{PATH}/gaussians/multiview\", exist_ok=True)\n",
    "output_multiview[\"gs\"].save_ply(f\"{PATH}/gaussians/multiview/{MULTI_VIEW_NAME}.ply\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which reconstruction to visualize (defaults to single-view output)\n",
    "visualization_output = output_multiview if 'output_multiview' in globals() else output\n",
    "visualization_name = MULTI_VIEW_NAME if 'output_multiview' in globals() else IMAGE_NAME\n",
    "visualization_dir = 'multiview' if 'output_multiview' in globals() else 'single'\n",
    "os.makedirs(f\"{PATH}/gaussians/{visualization_dir}\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Gaussian Splat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# render gaussian splat\n",
    "scene_gs = make_scene(visualization_output)\n",
    "scene_gs = ready_gaussian_for_video_rendering(scene_gs)\n",
    "\n",
    "video = render_video(\n",
    "    scene_gs,\n",
    "    r=1,\n",
    "    fov=60,\n",
    "    pitch_deg=15,\n",
    "    yaw_start_deg=-45,\n",
    "    resolution=512,\n",
    ")[\"color\"]\n",
    "\n",
    "# save video as gif\n",
    "imageio.mimsave(\n",
    "    os.path.join(f\"{PATH}/gaussians/{visualization_dir}/{visualization_name}.gif\"),\n",
    "    video,\n",
    "    format=\"GIF\",\n",
    "    duration=1000 / 30,  # default assuming 30fps from the input MP4\n",
    "    loop=0,  # 0 means loop indefinitely\n",
    ")\n",
    "\n",
    "# notebook display\n",
    "ImageDisplay(url=f\"gaussians/{visualization_dir}/{visualization_name}.gif?cache_invalidator={uuid.uuid4()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Interactive Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might take a while to load (black screen)\n",
    "interactive_visualizer(f\"{PATH}/gaussians/{visualization_dir}/{visualization_name}.ply\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
